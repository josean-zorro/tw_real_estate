
on:
  workflow_dispatch: # workflow_dispatch enables the workflow to be triggered manually
  schedule:           # Optionally schedule the crawler (e.g., every day at midnight)
    - cron: "0 4 1,11,21 * *"
jobs:
  meltano:
    runs-on: ubuntu-latest

    permissions:
      contents: 'read'
      id-token: 'write'
      actions: 'read'

    name: Meltano

    steps:
      # Checkout the repository so that a path to the action.yml can be used
      - uses: actions/checkout@v3

      # Authenticate to Google SDK for target-bigquery
      - name: Set up Cloud SDK
        uses: google-github-actions/auth@v2.0.0
        with:
          workload_identity_provider: '${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}'
          service_account: '${{ secrets.GCP_SERVICE_ACCOUNT }}'

      # Get the database files from the previous run, if exists
      - name: Download latest SQLite database artifact
        uses: dawidd6/action-download-artifact@v8
        continue-on-error: true
        with:
          workflow: ${{ github.workflow }}
          branch: main
          name: meltano.db
          path: ${{ github.workspace }}
          workflow_conclusion: completed

      # Determine the day of the month and set it as an output variable
      - name: Get Day of Month
        id: get_day
        run: |
          # Get the day of month as a number without a leading zero (e.g., 1, 11, 21)
          DAY=$(date +'%d' | sed 's/^0*//')
          echo "DAY_OF_MONTH=$DAY" >> $GITHUB_OUTPUT
          echo "Current day of month: $DAY"

      # Run the crawler:web_crawler command only on the 1st, 11th, or 21st day of the month
      - name: Run plvr crawler (conditional)
        if: steps.get_day.outputs.DAY_OF_MONTH == '1' || steps.get_day.outputs.DAY_OF_MONTH == '11' || steps.get_day.outputs.DAY_OF_MONTH == '21'
        uses: ./
        env:
          TARGET_BIGQUERY_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          MELTANO_DATABASE_URI: sqlite:////github/workspace/meltano.db
          MELTANO_ENVIRONMENT: prod
          PYTHONUNBUFFERED: 1
        with:
          args: | 
            meltano run crawler:web_crawler

      # Run the remaining Meltano commands that should execute every time the workflow is triggered
      - name: Run remaining Meltano commands
        uses: ./
        env:
          TARGET_BIGQUERY_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          MELTANO_DATABASE_URI: sqlite:////github/workspace/meltano.db
          MELTANO_ENVIRONMENT: prod
          PYTHONUNBUFFERED: 1
        with:
          args: |
            meltano el tap-spreadsheets-anywhere target-bigquery --state-id=plvr_el --catalog catalogs/plvr_catalog.json &&
            meltano invoke dbt-bigquery:deps &&
            meltano invoke dbt-bigquery:build

      # Upload the SQLite database containing incremental, bookmark state
      - name: Upload SQLite database artifact
        if: always() # Always run this step even if prior steps failed
        uses: actions/upload-artifact@v4
        with:
          name: meltano.db
          path: ${{ github.workspace }}/meltano.db*
